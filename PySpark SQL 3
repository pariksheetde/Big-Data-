from pyspark.sql import SparkSession
from pyspark.sql.types import *

# read the datafile from the location
team_sts = spark.read.csv("/FileStore/tables/game_teams_stats.csv", header = True, inferSchema = True)
# drop the unwanted columns
team_sts = team_sts.drop("powerPlayOpportunities","faceOffWinPercentage","giveaways","takeaways")
team_sts.show(5)

-------------------------------------------------------------------------------------------------------------------------------


from pyspark.sql import SparkSession
from pyspark.sql.types import *

ds = [StructField("game_id", IntegerType(),True),StructField("team_id", IntegerType(),True),StructField("HoA", StringType(),True),
     StructField("won", StringType(),True),StructField("settled_in", StringType(),True),StructField("head_coach", StringType(),True),
     StructField("goals", IntegerType(),True),StructField("shots", IntegerType(),True),StructField("hits", IntegerType(),True),
     StructField("pim", IntegerType(),True),StructField("powerPlayGoals", IntegerType(),True)]

fds = StructType(fields = ds)

# read the datafile from the location
team_sts = spark.read.csv("/FileStore/tables/game_teams_stats.csv", header = True, schema = fds)
# drop the unwanted columns
team_sts = team_sts.drop("powerPlayOpportunities","faceOffWinPercentage","giveaways","takeaways")
team_sts.show(5)
