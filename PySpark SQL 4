from pyspark.sql import SparkSession
import pyspark.sql.functions as f
from pyspark.sql.types import *

# read the datafile from the location
game = spark.read.csv("/FileStore/tables/game.csv", header = True, inferSchema = True)
game.createOrReplaceTempView("Game")

# read the datafile from the location
game_shift = spark.read.csv("/FileStore/tables/game_shifts_info.csv", header = True, inferSchema = True)
game_shift.createOrReplaceTempView("Game_Shift")

# df = spark.sql("select gm.game_id, gm.season, gm.type, gm.away_goals, gm.home_goals, gm.outcome, gm.venue, gm.home_rink_side_start, gs.player_id, gs.shift_start, gs.shift_end from game gm join game_shift gs on gm.game_id = gs.game_id")

df = spark.sql("select gm.game_id, gm.season, sum(gm.away_goals) as away_goals, sum(gm.home_goals) as home_goals from game gm join game_shift gs on gm.game_id = gs.game_id group by 1,2")

df.show()

-------------------------------------------------------------------------------------------------------------------------------

from pyspark.sql import SparkSession
import pyspark.sql.functions as f
from pyspark.sql.types import *

# read the datafile from the location
game = spark.read.csv("/FileStore/tables/game.csv", header = True, inferSchema = True)
game.createOrReplaceTempView("Game")

# read the datafile from the location
game_shift = spark.read.csv("/FileStore/tables/game_shifts_info.csv", header = True, inferSchema = True)
game_shift.createOrReplaceTempView("Game_Shift")

# df = spark.sql("select gm.game_id, gm.season, gm.type, gm.away_goals, gm.home_goals, gm.outcome, gm.venue, gm.home_rink_side_start, gs.player_id, gs.shift_start, gs.shift_end from game gm join game_shift gs on gm.game_id = gs.game_id")

df = spark.sql("select gm.game_id, gm.season, sum(gm.away_goals) as away_goals, sum(gm.home_goals) as home_goals, rank() over (order by gm.season asc) as rnk from game gm join game_shift gs on gm.game_id = gs.game_id group by 1,2")

df.show()

-------------------------------------------------------------------------------------------------------------------------------

from pyspark.sql import SparkSession
import pyspark.sql.functions as f
from pyspark.sql.types import *
from pyspark.sql.window import Window

# read the datafile from the location
game = spark.read.csv("/FileStore/tables/game.csv", header = True, inferSchema = True)
game.createOrReplaceTempView("Game")

# read the datafile from the location
game_shift = spark.read.csv("/FileStore/tables/game_shifts_info.csv", header = True, inferSchema = True)
game_shift.createOrReplaceTempView("Game_Shift")

# df = spark.sql("select gm.game_id, gm.season, gm.type, gm.away_goals, gm.home_goals, gm.outcome, gm.venue, gm.home_rink_side_start, gs.player_id, gs.shift_start, gs.shift_end from game gm join game_shift gs on gm.game_id = gs.game_id")

df = spark.sql("select * from (select gm.game_id, gm.season, sum(gm.away_goals) as away_goals, sum(gm.home_goals) as home_goals, rank() over (partition by gm.season order by gm.season asc) as rank from game gm join game_shift gs on gm.game_id = gs.game_id group by 1,2) a")

df.show()

-------------------------------------------------------------------------------------------------------------------------------

from pyspark.sql import SparkSession
import pyspark.sql.functions as f
from pyspark.sql.types import *
from pyspark.sql.window import Window

# read the datafile from the location
game = spark.read.csv("/FileStore/tables/game.csv", header = True, inferSchema = True)
game.createOrReplaceTempView("Game")

# read the datafile from the location
game_shift = spark.read.csv("/FileStore/tables/game_shifts_info.csv", header = True, inferSchema = True)
game_shift.createOrReplaceTempView("Game_Shift")

# df = spark.sql("select gm.game_id, gm.season, gm.type, gm.away_goals, gm.home_goals, gm.outcome, gm.venue, gm.home_rink_side_start, gs.player_id, gs.shift_start, gs.shift_end from game gm join game_shift gs on gm.game_id = gs.game_id")

df = spark.sql("select * from (select gm.game_id, gm.season, away_goals, home_goals, dense_rank() over (partition by gm.season order by gm.away_goals desc) as dense_rank from game gm join game_shift gs on gm.game_id = gs.game_id) a where dense_rank = 2")

df.show()

-------------------------------------------------------------------------------------------------------------------------------

from pyspark.sql import SparkSession
import pyspark.sql.functions as f
from pyspark.sql.types import *
from pyspark.sql.window import Window

# read the datafile from the location
game = spark.read.csv("/FileStore/tables/game.csv", header = True, inferSchema = True)
game.createOrReplaceTempView("Game")

# read the datafile from the location
game_shift = spark.read.csv("/FileStore/tables/game_shifts_info.csv", header = True, inferSchema = True)
game_shift.createOrReplaceTempView("Game_Shift")

# df = spark.sql("select gm.game_id, gm.season, gm.type, gm.away_goals, gm.home_goals, gm.outcome, gm.venue, gm.home_rink_side_start, gs.player_id, gs.shift_start, gs.shift_end from game gm join game_shift gs on gm.game_id = gs.game_id")

df = spark.sql("select * from (select gm.game_id, gm.season, away_goals, home_goals, dense_rank() over (partition by gm.season order by gm.away_goals desc) as dense_rank from game gm join game_shift gs on gm.game_id = gs.game_id) a where mod(dense_rank,2) = 0")

df.show(1000)

-------------------------------------------------------------------------------------------------------------------------------

from pyspark.sql import SparkSession
import pyspark.sql.functions as f
from pyspark.sql.types import *
from pyspark.sql.window import Window

# read the datafile from the location
game = spark.read.csv("/FileStore/tables/game.csv", header = True, inferSchema = True)
game.createOrReplaceTempView("Game")

# read the datafile from the location
game_shift = spark.read.csv("/FileStore/tables/game_shifts_info.csv", header = True, inferSchema = True)
game_shift.createOrReplaceTempView("Game_Shift")

# df = spark.sql("select gm.game_id, gm.season, gm.type, gm.away_goals, gm.home_goals, gm.outcome, gm.venue, gm.home_rink_side_start, gs.player_id, gs.shift_start, gs.shift_end from game gm join game_shift gs on gm.game_id = gs.game_id")

df = spark.sql("select * from(select gm.game_id, gm.season, sum(away_goals) as away_goals, sum(home_goals) as home_goals, rank() over (order by sum(away_goals) desc) as rank from game gm join game_shift gs on gm.game_id = gs.game_id group by 1,2) a")

df.show()

-------------------------------------------------------------------------------------------------------------------------------

from pyspark.sql import SparkSession
import pyspark.sql.functions as f
from pyspark.sql.types import *
from pyspark.sql.window import Window

# read the datafile from the location
game = spark.read.csv("/FileStore/tables/game.csv", header = True, inferSchema = True)
game.createOrReplaceTempView("Game")

# read the datafile from the location
game_shift = spark.read.csv("/FileStore/tables/game_shifts_info.csv", header = True, inferSchema = True)
game_shift.createOrReplaceTempView("Game_Shift")

# df = spark.sql("select gm.game_id, gm.season, gm.type, gm.away_goals, gm.home_goals, gm.outcome, gm.venue, gm.home_rink_side_start, gs.player_id, gs.shift_start, gs.shift_end from game gm join game_shift gs on gm.game_id = gs.game_id")

df = spark.sql("select * from(select gm.game_id, gm.season, sum(away_goals) as away_goals, sum(home_goals) as home_goals, rank() over (partition by gm.season order by sum(away_goals) desc) as rank from game gm join game_shift gs on gm.game_id = gs.game_id group by 1,2) a")

df.show()

-------------------------------------------------------------------------------------------------------------------------------

from pyspark.sql import SparkSession
import pyspark.sql.functions as f
from pyspark.sql.types import *
from pyspark.sql.window import Window

# read the datafile from the location
game = spark.read.csv("/FileStore/tables/game.csv", header = True, inferSchema = True)
game.createOrReplaceTempView("Game")

# read the datafile from the location
game_shift = spark.read.csv("/FileStore/tables/game_shifts_info.csv", header = True, inferSchema = True)
game_shift.createOrReplaceTempView("Game_Shift")

# df = spark.sql("select gm.game_id, gm.season, gm.type, gm.away_goals, gm.home_goals, gm.outcome, gm.venue, gm.home_rink_side_start, gs.player_id, gs.shift_start, gs.shift_end from game gm join game_shift gs on gm.game_id = gs.game_id")

df = spark.sql("select * from(select gm.game_id, gm.season, sum(away_goals) as away_goals, sum(home_goals) as home_goals, rank() over (partition by gm.season order by sum(away_goals) desc) as rank from game gm join game_shift gs on gm.game_id = gs.game_id group by 1,2) a where rank between 10 and 20")

df.show()

-------------------------------------------------------------------------------------------------------------------------------

from pyspark.sql import SparkSession
import pyspark.sql.functions as f
from pyspark.sql.types import *
from pyspark.sql.window import Window

# read the datafile from the location
game = spark.read.csv("/FileStore/tables/game.csv", header = True, inferSchema = True)
game.createOrReplaceTempView("Game")

# read the datafile from the location
game_shift = spark.read.csv("/FileStore/tables/game_shifts_info.csv", header = True, inferSchema = True)
game_shift.createOrReplaceTempView("Game_Shift")

# df = spark.sql("select gm.game_id, gm.season, gm.type, gm.away_goals, gm.home_goals, gm.outcome, gm.venue, gm.home_rink_side_start, gs.player_id, gs.shift_start, gs.shift_end from game gm join game_shift gs on gm.game_id = gs.game_id")

df = spark.sql("select * from(select gs.player_id, gm.game_id, gm.season, sum(away_goals) as away_goals, sum(home_goals) as home_goals, rank() over (partition by gm.season order by sum(away_goals) desc) as rank from game gm join game_shift gs on gm.game_id = gs.game_id group by 1,2,3) a")

df.show()

-------------------------------------------------------------------------------------------------------------------------------

from pyspark.sql import SparkSession
import pyspark.sql.functions as f
from pyspark.sql.types import *
from pyspark.sql.window import Window

# read the datafile from the location
game = spark.read.csv("/FileStore/tables/game.csv", header = True, inferSchema = True)
game.createOrReplaceTempView("Game")

# read the datafile from the location
game_shift = spark.read.csv("/FileStore/tables/game_shifts_info.csv", header = True, inferSchema = True)
game_shift.createOrReplaceTempView("Game_Shift")

# read the datafile from the location
player_info = spark.read.csv("/FileStore/tables/player_info.csv", header = True, inferSchema = True)
player_info.createOrReplaceTempView("Player_Info")

df = spark.sql("select * from(select gs.player_id, pi.firstname, pi.lastname, gm.game_id, gm.season, sum(away_goals) as away_goals, sum(home_goals) as home_goals, rank() over (partition by gm.season order by sum(away_goals) desc) as rank from game gm join game_shift gs on gm.game_id = gs.game_id join player_info pi on pi.player_id = gs.player_id group by 1,2,3,4,5) a")

df.show()

-------------------------------------------------------------------------------------------------------------------------------

from pyspark.sql import SparkSession
import pyspark.sql.functions as f
from pyspark.sql.types import *
from pyspark.sql.window import Window

# read the datafile from the location
game = spark.read.csv("/FileStore/tables/game.csv", header = True, inferSchema = True)
game.createOrReplaceTempView("Game")

# read the datafile from the location
game_shift = spark.read.csv("/FileStore/tables/game_shifts_info.csv", header = True, inferSchema = True)
game_shift.createOrReplaceTempView("Game_Shift")

# read the datafile from the location
player_info = spark.read.csv("/FileStore/tables/player_info.csv", header = True, inferSchema = True)
player_info.createOrReplaceTempView("Player_Info")

df = spark.sql("select * from(select gs.player_id, pi.firstname, pi.lastname, gm.game_id, gm.season, sum(away_goals) as away_goals, sum(home_goals) as home_goals, rank() over (partition by gm.season order by sum(away_goals) desc) as rank from game gm join game_shift gs on gm.game_id = gs.game_id join player_info pi on pi.player_id = gs.player_id group by 1,2,3,4,5 order by gs.player_id asc) a")

df.show()

-------------------------------------------------------------------------------------------------------------------------------
