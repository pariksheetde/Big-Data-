# Set everything to be logged to the console
log4j.rootCategory=WARN, console

# Define console appender
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.out
log4j.appender.console.layout=org.apache.log4j.PatternLayout
#log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

# Application log
log4j.logger.Bank=INFO, console, file
log4j.additivity.Bank=false

# Define rolling file appender
log4j.appender.file = org.apache.log4j.RollingFileAppender
#log4j.appender.file.File = {}

log4j.appender.file.ImmediateFlush = true
log4j.appender.file.Append = true
log4j.appender.file.MaxFileSize = 500MB
log4j.appender.file.MaxBackupIndex=2
log4j.appender.file.layout = org.apache.log4j.PatternLayout
log4j.appender.file.conversionPattern= %d{dd/MM/yyyy} %p %c{1}: %n%n

#Recommendation for spark template
log4j.logger.org.apache.spark.repl.Main = WARN
log4j.logger.org.spark_project.jetty = WARN
log4j.logger.org.spark_project.jetty.util.component.AbstractLifeCycle = ERROR
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper = INFO
log4j.logger.org.apache.spark.repl.SparkIMain$SparkILoopInterpreter = INFO
log4j.logger.org.apache.parquet = ERROR
log4j.logger.parquet = ERROR
log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler = FATAL
log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry = ERROR
